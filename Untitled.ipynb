{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc81fe9-43af-40f2-a944-c85183b40600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|█████████████████| 8.82M/8.82M [00:01<00:00, 6.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header 0 Publish 25 Company 24 Ort 25 Desc 0 Link 0\n",
      "DataFrame End : (25, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:01:06.372284\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Define functions\n",
    "# Sleep function \n",
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "\n",
    "# Wait for a certain measure of time before throwing an exception\n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "\n",
    "# Click Function\n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "# Find Elements Function\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "\n",
    "# Scroll Down Function\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)\n",
    "        \n",
    "        \n",
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned \n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Business Analyst'\n",
    "#job_name = 'Data Analyst'\n",
    "#job_name = 'Data Scientist'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.utils import ChromeType\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "chrome_service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())\n",
    "\n",
    "chrome_options = Options()\n",
    "options = [\n",
    "    \"--headless\",\n",
    "    \"--disable-gpu\",\n",
    "    \"--window-size=1920,1200\",\n",
    "    \"--ignore-certificate-errors\",\n",
    "    \"--disable-extensions\",\n",
    "    \"--no-sandbox\",\n",
    "    \"--disable-dev-shm-usage\"\n",
    "]\n",
    "for option in options:\n",
    "    chrome_options.add_argument(option)\n",
    "\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Workflow_github/chromedriver'\n",
    "#driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-1uvdp0v', 'resultlist-w7zbt7', 'resultlist-1va1dj8', 'resultlist-suri3e'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# 4.2 - Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'resultlist-1fp8oay')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'resultlist-1jx3vjx')\n",
    "\n",
    "\n",
    "# 4.3 - Get Links\n",
    "header = driver.find_elements(By.CLASS_NAME, H)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "# 4.4 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company[1:]), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# 4.5 - Total Search Page Number\n",
    "#list_result = [res.text for res in result]\n",
    "#number_of_page = int(list_result[-2])\n",
    "#print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.6 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "'''\n",
    "# 4.7 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.7.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.7.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "    list_description = [des.text for des in description]\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_link = [link.get_attribute('href') for link in header]\n",
    " \n",
    "    # 4.7.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.7.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "'''\n",
    "\n",
    "# 5.1 - Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df['date'] = time_\n",
    "job_name2 = job_name.replace(' ', '_')\n",
    "df['search_title'] = job_name2\n",
    "\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Workflow_github/data'\n",
    "job_name3 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name3}-{time_}.csv', index=False)\n",
    "\n",
    "# 6 - Quit\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb64b5-512e-4a78-aa32-0d8ec35752ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
